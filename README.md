# Revenue Analysis Using PySpark, Python, and Databricks

## Project Overview

This project leverages PySpark, Python, and Databricks to analyze sales data and extract meaningful insights. The primary focus is on customer segmentation, revenue trends, and churn analysis to enhance business decision-making.

## Tech Stack

PySpark: For distributed data processing and analysis.

Python: For data transformation and visualization.

Databricks: For scalable data analysis and collaboration.

Matplotlib & Seaborn: For data visualization.

Plotly: For interactive charts.

## Key Objectives

Identify top customers based on revenue and purchase frequency.

Perform RFM analysis to segment customers.

Conduct churn analysis to identify inactive customers.

Visualize monthly sales trends with month names instead of numbers.

Analyze peak sales hours using various visualizations.

Determine top-selling products and their contribution to revenue.

Identify countries contributing the most to revenue.

## Data Processing Steps

Data Cleaning: Removed null values, duplicates, and irrelevant records.

Feature Engineering: Created new columns for revenue, purchase frequency, and recency.

RFM Analysis: Categorized customers into segments based on Recency, Frequency, and Monetary value.

Churn Analysis: Identified customers inactive for more than 180 days.

## Visualization:

Bar charts for revenue by country.

Line charts for monthly sales trends.

Heatmaps for peak sales hours.

Scatter plots for customer segmentation.

## Results & Insights

United Kingdom generated the highest revenue, followed by Netherlands and Ireland.

Customers with high purchase frequency and high monetary value were identified as loyal customers.

Sales peaked during specific hours of the day, enabling targeted marketing strategies.

Monthly sales trends showed seasonal variations, assisting in inventory planning.
